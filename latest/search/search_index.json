{
    "docs": [
        {
            "location": "/", 
            "text": "BioMedQuery Julia Package\n\n\nJulia utilities to process and save results from BioMedical databases/APIs.\n\n\nBioServices.jl\n (part of BioJulia) provides the basic interface to some of the APIs, while BioMedQuery helps parse and save results into MySQL, SQLite, DataFrames, CSV etc.\n\n\nSupported APIs include:\n\n\nNational Library of Medicine (NLM)\n\n\n\n\nEntrez Programming Utilities \n(E-Utilities)\n\n\nUnified Medical Language System \n(UMLS)\n\n\nClinical Trials \n(clinicaltrials.gov)\n\n\nMEDLINE \n(PubMed MEDLINE)\n\n\n\n\n\n\nInstallation\n\n\nBioMedQuery is a registered package. To install the latest \nstable version\n, use the package manager.\n\n\nPkg\n.\nadd\n(\nBioMedQuery\n)\n\n\n\n\n\n\nTo chekout the current master (development) branch:\n\n\nPkg\n.\ncheckout\n(\nBioMedQuery\n)\n\n\n\n\n\n\n`\n\n\n\n\nRelated Packages\n\n\n\n\n\n\n\n\nFunction\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nBioServices.jl\n\n\nInterface to EUtils and UMLS APIs\n\n\n\n\n\n\nPubMedMiner.jl\n\n\nExamples of comorbidity studies using PubMed articles", 
            "title": "Home"
        }, 
        {
            "location": "/#biomedquery-julia-package", 
            "text": "Julia utilities to process and save results from BioMedical databases/APIs.  BioServices.jl  (part of BioJulia) provides the basic interface to some of the APIs, while BioMedQuery helps parse and save results into MySQL, SQLite, DataFrames, CSV etc.  Supported APIs include:  National Library of Medicine (NLM)   Entrez Programming Utilities  (E-Utilities)  Unified Medical Language System  (UMLS)  Clinical Trials  (clinicaltrials.gov)  MEDLINE  (PubMed MEDLINE)", 
            "title": "BioMedQuery Julia Package"
        }, 
        {
            "location": "/#installation", 
            "text": "BioMedQuery is a registered package. To install the latest  stable version , use the package manager.  Pkg . add ( BioMedQuery )   To chekout the current master (development) branch:  Pkg . checkout ( BioMedQuery )   `", 
            "title": "Installation"
        }, 
        {
            "location": "/#related-packages", 
            "text": "Function  Description      BioServices.jl  Interface to EUtils and UMLS APIs    PubMedMiner.jl  Examples of comorbidity studies using PubMed articles", 
            "title": "Related Packages"
        }, 
        {
            "location": "/examples/", 
            "text": "The repository contains an \nexamples folder\n with jupyter notebooks demonstrating how to use BioMedQuery's pre-assembled high-level processes and workflows.\n\n\nNote: \n When working with the notebooks, a corresponding julia script is generated automatically on every save. For this feature to work properly, make sure you have \nnbconvert\n installed.\n\n\nThe following examples are available:\n\n\n\n\n\n\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSearch and Save PubMed Queries\n\n\nSearch pubmed, parse results and store using MySQL or SQLite backend, or export to a  citation library\n\n\n\n\n\n\nBuild MESH-UMLS map\n\n\nFor all MeSH descriptors in a given database, build a table to match them to their UMLS concept\n\n\n\n\n\n\nOccurrence Matrix\n\n\nBuild a occurrence matrix indicating papers associated with MeSH descriptors of a given UMLS concept\n\n\n\n\n\n\nExporting Citations\n\n\nExport the citation for one or more PMIDs to a Endnote/Bibtex file", 
            "title": "Overview"
        }, 
        {
            "location": "/example1/", 
            "text": "", 
            "title": "Pubmed Search and Save"
        }, 
        {
            "location": "/example2/", 
            "text": "", 
            "title": "MeSH/UMLS Map"
        }, 
        {
            "location": "/example3/", 
            "text": "", 
            "title": "UMLS Semantic Filtering"
        }, 
        {
            "location": "/example4/", 
            "text": "", 
            "title": "Export to citations"
        }, 
        {
            "location": "/processes/", 
            "text": "This module provides common processes/workflows when using the BioMedQuery utilities. For instance, searching PubMed, requires calling the NCBI e-utils in a particular order. After the search, the results are often saved to the database. This module contains pre-assembled functions performing all necessary steps. To see sample scripts that use this processes, refer to the following \nsection\n\n\nImport\n\n\nusing BioMedQuery.Processes\n\n\n\n\n\n\n\nIndex\n\n\n\n\nBioMedQuery.Processes.close_cons\n\n\nBioMedQuery.Processes.export_citation\n\n\nBioMedQuery.Processes.export_citation\n\n\nBioMedQuery.Processes.get_file_name\n\n\nBioMedQuery.Processes.get_ftp_con\n\n\nBioMedQuery.Processes.get_ml_file\n\n\nBioMedQuery.Processes.init_medline\n\n\nBioMedQuery.Processes.load_medline\n\n\nBioMedQuery.Processes.map_mesh_to_umls!\n\n\nBioMedQuery.Processes.map_mesh_to_umls_async!\n\n\nBioMedQuery.Processes.parse_ml_file\n\n\nBioMedQuery.Processes.pubmed_search_and_parse\n\n\nBioMedQuery.Processes.pubmed_search_and_save!\n\n\nBioMedQuery.Processes.umls_semantic_occurrences\n\n\n\n\n\n\nFunctions\n\n\n#\n\n\nBioMedQuery.Processes.export_citation\n \n \nFunction\n.\n\n\nexport_citation(pmid::Int64, citation_type, output_file,verbose)\n\n\n\n\n\nExport, to an output file, the citation for PubMed article identified by the given pmid\n\n\nArguments\n\n\n\n\ncitation_type::String\n: At the moment supported types include: \"endnote\"\n\n\n\n\nsource\n\n\n#\n\n\nBioMedQuery.Processes.export_citation\n \n \nFunction\n.\n\n\nexport_citation(pmids::Vector{Int64}, citation_type, output_file,verbose)\n\n\n\n\n\nExport, to an output file, the citation for collection of PubMed articles identified by the given pmids\n\n\nArguments\n\n\n\n\ncitation_type::String\n: At the moment supported types include: \"endnote\"\n\n\n\n\nsource\n\n\n#\n\n\nBioMedQuery.Processes.load_medline\n \n \nMethod\n.\n\n\nload_medline(db_con, output_dir; start_file = 1, end_file = 928, year=2018, test=false)\n\n\n\n\n\nGiven a MySQL connection and optionally the start and end files, fetches the medline files, parses the xml, and loads into a MySQL DB (assumes tables already exist). The raw (xml.gz) and parsed (csv) files will be stored in the output_dir.\n\n\nArguments\n\n\n\n\ndb_con: A MySQL Connection to a db (tables must already be created - see PubMed.create_tables!)\n\n\noutput_dir : root directory where the raw and parsed files should be stored\n\n\nstart_file : which medline file should the loading start at\n\n\nend_file: which medline file should the loading end at (default is last file in 2018 baseline)\n\n\nyear: which year medline is (current is 2018)\n\n\ntest: if true, a sample file will be downloaded, parsed, and loaded instead of the baseline files\n\n\n\n\nsource\n\n\n#\n\n\nBioMedQuery.Processes.map_mesh_to_umls!\n \n \nMethod\n.\n\n\nmap_mesh_to_umls!(db, c::Credentials)\n\n\nBuild and store in the given database a map from MESH descriptors to UMLS Semantic Concepts\n\n\nArguments\n\n\n\n\ndb\n: Database. Must contain TABLE:mesh_descriptor. For each of the\n\n\n\n\ndescriptors in that table, search and insert the associated semantic concepts into a new (cleared) TABLE:mesh2umls\n\n\n\n\nc::Credentials\n: UMLS username and password\n\n\n\n\nsource\n\n\n#\n\n\nBioMedQuery.Processes.map_mesh_to_umls_async!\n \n \nMethod\n.\n\n\nmap_mesh_to_umls_async\n!(\ndb\n,\n \nc\n::\nCredentials\n;\n \ntimeout\n,\n \nappend_results\n,\n \nverbose\n)\n\n\n\nBuild\n \n(\nusing\n \nasync\n \nUMLS-API\n \ncalls\n)\n \nand\n \nstore\n \nin\n \nthe\n \ngiven\n \ndatabase\n \na\n \nmap\n \nfrom\n\n\n\n\n\n\nMESH descriptors to UMLS Semantic Concepts. For large queies this function will be faster than it's synchrounous counterpart\n\n\nArguments\n\n\n\n\ndb\n: Database. Must contain TABLE:mesh_descriptor. For each of the\n\n\n\n\ndescriptors in that table, search and insert the associated semantic concepts into a new (cleared) TABLE:mesh2umls\n\n\n\n\nc::Credentials\n: UMLS username and password\n\n\nappend_results::Bool\n : If false a NEW and EMPTY mesh2umls database table in creted\n\n\n\n\nsource\n\n\n#\n\n\nBioMedQuery.Processes.pubmed_search_and_parse\n \n \nFunction\n.\n\n\npubmed_search_and_parse(email, search_term::String, article_max, verbose=false)\n\n\n\n\n\nSearch pubmed and parse the results into a dictionary of DataFrames.  The dataframes have the same names and fields as the pubmed database schema. (e.g. df_dict[\"basic\"] returns a dataframe with the basic article info)\n\n\nArguments\n\n\n\n\nemail: valid email address (otherwise pubmed may block you)\n\n\nsearch_term : search string to submit to PubMed\n\n\n\n\ne.g (asthma[MeSH Terms]) AND (\"2001/01/29\"[Date - Publication] : \"2010\"[Date - Publication]) see http://www.ncbi.nlm.nih.gov/pubmed/advanced for help constructing the string\n\n\n\n\narticle_max : maximum number of articles to return\n\n\nverbose: if true, the NCBI xml response files are saved to current directory\n\n\n\n\nsource\n\n\n#\n\n\nBioMedQuery.Processes.pubmed_search_and_save!\n \n \nFunction\n.\n\n\npubmed_search_and_save!(email, search_term::String, article_max,\nconn, verbose=false)\n\n\n\n\n\nSearch pubmed and save the results into a database connection. The database is expected to exist and have the appriate pubmed related tables. You can create such tables using \nPubMed.create_tables(conn)\n\n\nArguments\n\n\n\n\nemail: valid email address (otherwise pubmed may block you)\n\n\nsearch_term : search string to submit to PubMed\n\n\n\n\ne.g (asthma[MeSH Terms]) AND (\"2001/01/29\"[Date - Publication] : \"2010\"[Date - Publication]) see http://www.ncbi.nlm.nih.gov/pubmed/advanced for help constructing the string\n\n\n\n\narticle_max : maximum number of articles to return\n\n\nconn: database connection\n\n\nverbose: if true, the NCBI xml response files are saved to current directory\n\n\n\n\nsource\n\n\n#\n\n\nBioMedQuery.Processes.umls_semantic_occurrences\n \n \nMethod\n.\n\n\numls_semantic_occurrences(db, umls_semantic_type)\n\n\nReturn a sparse matrix indicating the presence of MESH descriptors associated with a given umls semantic type in all articles of the input database\n\n\nOutput\n\n\n\n\ndes_ind_dict\n: Dictionary matching row number to descriptor names\n\n\ndisease_occurances\n : Sparse matrix. The columns correspond to a feature\n\n\n\n\nvector, where each row is a MESH descriptor. There are as many columns as articles. The occurance/abscense of a descriptor is labeled as 1/0\n\n\nsource\n\n\n#\n\n\nBioMedQuery.Processes.close_cons\n \n \nMethod\n.\n\n\nclose_cons(ftp_con)\n\n\n\n\n\ncloses connection and cleans up\n\n\nsource\n\n\n#\n\n\nBioMedQuery.Processes.get_file_name\n \n \nFunction\n.\n\n\nget_file_name(fnum::Int, year::Int = 2018, test = false)\n\n\n\n\n\nReturns the medline file name given the file number and year.\n\n\nsource\n\n\n#\n\n\nBioMedQuery.Processes.get_ftp_con\n \n \nFunction\n.\n\n\nget_ftp_con(test = false)\n\n\n\n\n\nGet an FTP connection\n\n\nsource\n\n\n#\n\n\nBioMedQuery.Processes.get_ml_file\n \n \nMethod\n.\n\n\nget_ml_file(fname::String, conn::ConnContext, output_dir)\n\n\n\n\n\nRetrieves the file with fname and puts in medline/raw_files.  Returns the HTTP response.\n\n\nsource\n\n\n#\n\n\nBioMedQuery.Processes.init_medline\n \n \nFunction\n.\n\n\ninit_medline(output_dir, test=false)\n\n\n\n\n\nSets up environment (folders), and connects to medline FTP Server and returns the connection.\n\n\nsource\n\n\n#\n\n\nBioMedQuery.Processes.parse_ml_file\n \n \nMethod\n.\n\n\nparse_ml_file(fname::String, output_dir::String)\n\n\n\n\n\nParses the medline xml file into a dictionary of dataframes. Saves the resulting CSV files to medline/parsed_files.\n\n\nsource", 
            "title": "Processes/Workflows"
        }, 
        {
            "location": "/processes/#import", 
            "text": "using BioMedQuery.Processes", 
            "title": "Import"
        }, 
        {
            "location": "/processes/#index", 
            "text": "BioMedQuery.Processes.close_cons  BioMedQuery.Processes.export_citation  BioMedQuery.Processes.export_citation  BioMedQuery.Processes.get_file_name  BioMedQuery.Processes.get_ftp_con  BioMedQuery.Processes.get_ml_file  BioMedQuery.Processes.init_medline  BioMedQuery.Processes.load_medline  BioMedQuery.Processes.map_mesh_to_umls!  BioMedQuery.Processes.map_mesh_to_umls_async!  BioMedQuery.Processes.parse_ml_file  BioMedQuery.Processes.pubmed_search_and_parse  BioMedQuery.Processes.pubmed_search_and_save!  BioMedQuery.Processes.umls_semantic_occurrences", 
            "title": "Index"
        }, 
        {
            "location": "/processes/#functions", 
            "text": "#  BioMedQuery.Processes.export_citation     Function .  export_citation(pmid::Int64, citation_type, output_file,verbose)  Export, to an output file, the citation for PubMed article identified by the given pmid  Arguments   citation_type::String : At the moment supported types include: \"endnote\"   source  #  BioMedQuery.Processes.export_citation     Function .  export_citation(pmids::Vector{Int64}, citation_type, output_file,verbose)  Export, to an output file, the citation for collection of PubMed articles identified by the given pmids  Arguments   citation_type::String : At the moment supported types include: \"endnote\"   source  #  BioMedQuery.Processes.load_medline     Method .  load_medline(db_con, output_dir; start_file = 1, end_file = 928, year=2018, test=false)  Given a MySQL connection and optionally the start and end files, fetches the medline files, parses the xml, and loads into a MySQL DB (assumes tables already exist). The raw (xml.gz) and parsed (csv) files will be stored in the output_dir.", 
            "title": "Functions"
        }, 
        {
            "location": "/processes/#arguments", 
            "text": "db_con: A MySQL Connection to a db (tables must already be created - see PubMed.create_tables!)  output_dir : root directory where the raw and parsed files should be stored  start_file : which medline file should the loading start at  end_file: which medline file should the loading end at (default is last file in 2018 baseline)  year: which year medline is (current is 2018)  test: if true, a sample file will be downloaded, parsed, and loaded instead of the baseline files   source  #  BioMedQuery.Processes.map_mesh_to_umls!     Method .  map_mesh_to_umls!(db, c::Credentials)  Build and store in the given database a map from MESH descriptors to UMLS Semantic Concepts", 
            "title": "Arguments"
        }, 
        {
            "location": "/processes/#arguments_1", 
            "text": "db : Database. Must contain TABLE:mesh_descriptor. For each of the   descriptors in that table, search and insert the associated semantic concepts into a new (cleared) TABLE:mesh2umls   c::Credentials : UMLS username and password   source  #  BioMedQuery.Processes.map_mesh_to_umls_async!     Method .  map_mesh_to_umls_async !( db ,   c :: Credentials ;   timeout ,   append_results ,   verbose )  Build   ( using   async   UMLS-API   calls )   and   store   in   the   given   database   a   map   from   MESH descriptors to UMLS Semantic Concepts. For large queies this function will be faster than it's synchrounous counterpart", 
            "title": "Arguments"
        }, 
        {
            "location": "/processes/#arguments_2", 
            "text": "db : Database. Must contain TABLE:mesh_descriptor. For each of the   descriptors in that table, search and insert the associated semantic concepts into a new (cleared) TABLE:mesh2umls   c::Credentials : UMLS username and password  append_results::Bool  : If false a NEW and EMPTY mesh2umls database table in creted   source  #  BioMedQuery.Processes.pubmed_search_and_parse     Function .  pubmed_search_and_parse(email, search_term::String, article_max, verbose=false)  Search pubmed and parse the results into a dictionary of DataFrames.  The dataframes have the same names and fields as the pubmed database schema. (e.g. df_dict[\"basic\"] returns a dataframe with the basic article info)", 
            "title": "Arguments"
        }, 
        {
            "location": "/processes/#arguments_3", 
            "text": "email: valid email address (otherwise pubmed may block you)  search_term : search string to submit to PubMed   e.g (asthma[MeSH Terms]) AND (\"2001/01/29\"[Date - Publication] : \"2010\"[Date - Publication]) see http://www.ncbi.nlm.nih.gov/pubmed/advanced for help constructing the string   article_max : maximum number of articles to return  verbose: if true, the NCBI xml response files are saved to current directory   source  #  BioMedQuery.Processes.pubmed_search_and_save!     Function .  pubmed_search_and_save!(email, search_term::String, article_max,\nconn, verbose=false)  Search pubmed and save the results into a database connection. The database is expected to exist and have the appriate pubmed related tables. You can create such tables using  PubMed.create_tables(conn)", 
            "title": "Arguments"
        }, 
        {
            "location": "/processes/#arguments_4", 
            "text": "email: valid email address (otherwise pubmed may block you)  search_term : search string to submit to PubMed   e.g (asthma[MeSH Terms]) AND (\"2001/01/29\"[Date - Publication] : \"2010\"[Date - Publication]) see http://www.ncbi.nlm.nih.gov/pubmed/advanced for help constructing the string   article_max : maximum number of articles to return  conn: database connection  verbose: if true, the NCBI xml response files are saved to current directory   source  #  BioMedQuery.Processes.umls_semantic_occurrences     Method .  umls_semantic_occurrences(db, umls_semantic_type)  Return a sparse matrix indicating the presence of MESH descriptors associated with a given umls semantic type in all articles of the input database", 
            "title": "Arguments"
        }, 
        {
            "location": "/processes/#output", 
            "text": "des_ind_dict : Dictionary matching row number to descriptor names  disease_occurances  : Sparse matrix. The columns correspond to a feature   vector, where each row is a MESH descriptor. There are as many columns as articles. The occurance/abscense of a descriptor is labeled as 1/0  source  #  BioMedQuery.Processes.close_cons     Method .  close_cons(ftp_con)  closes connection and cleans up  source  #  BioMedQuery.Processes.get_file_name     Function .  get_file_name(fnum::Int, year::Int = 2018, test = false)  Returns the medline file name given the file number and year.  source  #  BioMedQuery.Processes.get_ftp_con     Function .  get_ftp_con(test = false)  Get an FTP connection  source  #  BioMedQuery.Processes.get_ml_file     Method .  get_ml_file(fname::String, conn::ConnContext, output_dir)  Retrieves the file with fname and puts in medline/raw_files.  Returns the HTTP response.  source  #  BioMedQuery.Processes.init_medline     Function .  init_medline(output_dir, test=false)  Sets up environment (folders), and connects to medline FTP Server and returns the connection.  source  #  BioMedQuery.Processes.parse_ml_file     Method .  parse_ml_file(fname::String, output_dir::String)  Parses the medline xml file into a dictionary of dataframes. Saves the resulting CSV files to medline/parsed_files.  source", 
            "title": "Output"
        }, 
        {
            "location": "/pubmed/", 
            "text": "Utility functions to parse and store PubMed searches via \nBioServices.EUtils\n\n\n\n\nImport Module\n\n\nusing BioMedQuery.PubMed\n\n\n\n\n\nThis module provides utility functions to parse, store and export queries to PubMed via the NCBI EUtils and its julia interface \nBioServices.EUtils\n. For many purposes you may interact with the higher level pipelines in [BioMedQuery.Processes]. Here, some of the lower level functions are discussed in case you need to assemble different pipelines.\n\n\n\n\nBasics of searching PubMed\n\n\nWe are often interested in searching PubMed for all articles related to a search term, and possibly restricted by other search criteria. To do so we use \nBioServices.EUtils\n. A basic example of how we may use the functions \nesearch\n and \nefetch\n to accomplish such task is illustrated below.\n\n\nusing\n \nBioServices\n.\nEUtils\n\n\nusing\n \nXMLDict\n\n\nusing\n \nEzXML\n\n\n\nsearch_term\n \n=\n \nobstructive sleep apnea[MeSH Major Topic]\n\n\n\n#esearch\n\n\nesearch_response\n \n=\n \nesearch\n(\ndb\n=\npubmed\n,\n \nterm\n \n=\n \nsearch_term\n,\n\n\nretstart\n \n=\n \n0\n,\n \nretmax\n \n=\n \n20\n,\n \ntool\n \n=\nBioJulia\n)\n\n\n\n#convert xml to dictionary\n\n\nesearch_dict\n \n=\n \nparse_xml\n(\nString\n(\nesearch_response\n.\ndata\n))\n\n\n\n#convert id\ns to a array of numbers\n\n\nids\n \n=\n \n[\nparse\n(\nInt64\n,\n \nid_node\n)\n \nfor\n \nid_node\n \nin\n \nesearch_dict\n[\nIdList\n][\nId\n]]\n\n\n\n#efetch\n\n\nefetch_response\n \n=\n \nefetch\n(\ndb\n \n=\n \npubmed\n,\n \ntool\n \n=\n \nBioJulia\n,\n \nretmode\n \n=\n \nxml\n,\n \nrettype\n \n=\n \nnull\n,\n \nid\n \n=\n \nids\n)\n\n\n\n#convert xml to xml node tree\n\n\nefetch_doc\n \n=\n \nroot\n(\nparsexml\n(\nString\n(\nefetch_response\n.\ndata\n)))\n\n\n\n\n\n\n\n\nHandling XML responses\n\n\nMany APIs return responses in XML form.\n\n\nTo parse an XML to a Julia dictionary we can use the XMLDict package\n\n\nusing\n \nXMLDict\n\n\ndict\n \n=\n \nparse_xml\n(\nString\n(\nresponse\n.\ndata\n))\n  \n\n\n\n\n\nYou can save directly the XML String to file\n\n\nxdoc\n \n=\n \nparse_string\n(\nesearch\n)\n\n\nsave_file\n(\nxdoc\n,\n \n./file.xml\n)\n\n\n\n\n\n\n\n\n\n\nSave eseach/efetch responses\n\n\n\n\nSave PMIDs to MySQL\n\n\nIf we are only interseted in saving a list of PMIDs associated with a query, we can do so as follows\n\n\ndbname\n \n=\n \nentrez_test\n\n\nhost\n \n=\n \n127.0.0.1\n;\n\n\nuser\n \n=\n \nroot\n\n\npwd\n \n=\n \n\n\n\n#Collect PMIDs from esearch result\n\n\nids\n \n=\n \nArray\n{\nInt64\n,\n1\n}()\n\n\nfor\n \nid_node\n \nin\n \nesearch_dict\n[\nIdList\n][\nId\n]\n\n    \npush!\n(\nids\n,\n \nparse\n(\nInt64\n,\n \nid_node\n))\n\n\nend\n\n\n\n# Initialize or connect to database\n\n\nconst\n \nconn\n \n=\n \nDBUtils\n.\ninit_mysql_database\n(\nhost\n,\n \nuser\n,\n \npwd\n,\n \ndbname\n)\n\n\n\n# Create `article` table to store pmids\n\n\nPubMed\n.\ncreate_pmid_table!\n(\nconn\n)\n\n\n\n#Save pmids\n\n\nPubMed\n.\nsave_pmids!\n(\nconn\n,\n \nids\n)\n\n\n\n#query the article table to explore list of pmids\n\n\nall_pmids\n \n=\n \nBioMedQuery\n.\nPubMed\n.\nall_pmids\n(\nconn\n)\n\n\n\n\n\n\n\n\nExport efetch response as EndNote citation file\n\n\nWe can export the information returned by efetch as and EndNote/BibTex library file\n\n\ncitation\n \n=\n \nPubMed\n.\nCitationOutput\n(\nendnote\n,\n \n./citations_temp.endnote\n,\n \ntrue\n)\n\n\nnsucceses\n \n=\n \nPubMed\n.\nsave_efetch!\n(\ncitation\n,\n \nefetch_doc\n,\n \nverbose\n)\n\n\n\n\n\n\n\n\nSave efetch response to MySQL database\n\n\nSave the information returned by efetch to a MySQL database\n\n\ndbname\n \n=\n \nefetch_test\n\n\nhost\n \n=\n \n127.0.0.1\n;\n\n\nuser\n \n=\n \nroot\n\n\npwd\n \n=\n \n\n\n\n# Save results of efetch to database and cleanup intermediate CSV files\n\n\nconst\n \nconn\n \n=\n \nDBUtils\n.\ninit_mysql_database\n(\nhost\n,\n \nuser\n,\n \npwd\n,\n \ndbname\n)\n\n\nPubMed\n.\ncreate_tables!\n(\nconn\n)\n\n\nPubMed\n.\nsave_efetch!\n(\nconn\n,\n \nefetch_doc\n,\n \nfalse\n,\n \ntrue\n)\n \n# verbose = false, drop_csv = true\n\n\n\n\n\n\n\n\nSave efetch response to SQLite database\n\n\nSave the information returned by efetch to a MySQL database\n\n\ndb_path\n \n=\n \n./test_db.db\n\n\n\nconst\n \nconn\n \n=\n \nSQLite\n.\nDB\n(\ndb_path\n)\n\n\nPubMed\n.\ncreate_tables!\n(\nconn\n)\n\n\nPubMed\n.\nsave_efetch!\n(\nconn\n,\n \nefetch_doc\n)\n\n\n\n\n\n\n\n\nReturn efetch response as a dictionary of DataFrames\n\n\nThe information returned by efetch can also be returned as dataframes. The dataframes match the format of the tables that are created for the sql saving functions (schema image below). These dataframes can also easily be saved to csv files.\n\n\n    \ndfs\n \n=\n \nPubMed\n.\nparse\n(\nefetch_doc\n)\n\n\n    \nPubMed\n.\ndfs_to_csv\n(\ndfs\n,\n \nmy/path\n,\n \nmy_file_prefix_\n)\n\n\n\n\n\n\n\n\nExploring output databases\n\n\nThe following schema has been used to store the results. If you are interested in having this module store additional fields, feel free to open an issue        \n\n\n\n\nWe can also explore the tables using BioMedQuery.DBUtils, e,g\n\n\ntables\n \n=\n \n[\nauthor_ref\n,\n \nmesh_desc\n,\n\n\nmesh_qual\n,\n \nmesh_heading\n]\n\n\n\nfor\n \nt\n \nin\n \ntables\n\n    \nquery_str\n \n=\n \nSELECT * FROM \n*\nt\n*\n LIMIT 10;\n\n    \nq\n \n=\n \nDBUtils\n.\ndb_query\n(\ndb\n,\n \nquery_str\n)\n\n    \nprintln\n(\nq\n)\n\n\nend\n\n\n\n\n\n\n\n\n\n\nIndex\n\n\n\n\nBioMedQuery.PubMed.abstracts\n\n\nBioMedQuery.PubMed.abstracts_by_year\n\n\nBioMedQuery.PubMed.all_mesh\n\n\nBioMedQuery.PubMed.all_pmids\n\n\nBioMedQuery.PubMed.citations_bibtex\n\n\nBioMedQuery.PubMed.citations_endnote\n\n\nBioMedQuery.PubMed.create_pmid_table!\n\n\nBioMedQuery.PubMed.create_tables!\n\n\nBioMedQuery.PubMed.dfs_to_csv\n\n\nBioMedQuery.PubMed.dict_to_array\n\n\nBioMedQuery.PubMed.get_article_mesh\n\n\nBioMedQuery.PubMed.get_article_mesh_by_concept\n\n\nBioMedQuery.PubMed.parse_MedlineDate\n\n\nBioMedQuery.PubMed.parse_author\n\n\nBioMedQuery.PubMed.parse_month\n\n\nBioMedQuery.PubMed.parse_orcid\n\n\nBioMedQuery.PubMed.parse_year\n\n\nBioMedQuery.PubMed.remove_csvs\n\n\nBioMedQuery.PubMed.remove_csvs\n\n\nBioMedQuery.PubMed.save_efetch!\n\n\nBioMedQuery.PubMed.save_efetch!\n\n\nBioMedQuery.PubMed.save_pmids!\n\n\n\n\n\n\nStructs and Functions\n\n\n#\n\n\nBase.parse\n \n \nMethod\n.\n\n\nparse(xml::EzXML.Node)\n\n\n\n\n\nParses a PubMedArticleSet that matches the NCBI-XML format\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.abstracts\n \n \nMethod\n.\n\n\nabstracts(db; local_medline=false)\n\n\nReturn all abstracts related to PMIDs in the database. If local_medline flag is set to true, it is assumed that db contains \nbasic\n table with only PMIDs and all other info is available in a (same host) medline database\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.abstracts_by_year\n \n \nMethod\n.\n\n\nabstracts_by_year(db, pub_year; local_medline=false)\n\n\nReturn all abstracts of article published in the given year. If local_medline flag is set to true, it is assumed that db contains \narticle\n table with only PMIDs and all other info is available in a (same host) medline database\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.all_pmids\n \n \nMethod\n.\n\n\nall_pmids(db)\n\n\n\n\n\nReturn all PMIDs stored in the \narticle\n table of the input database\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.citations_bibtex\n \n \nFunction\n.\n\n\ncitations_bibtex(article::Dict{String,DataFrame}, verbose=false)\n\n\n\n\n\nTransforms a Dictionary of pubmed dataframes into text corresponding to its bibtex citation\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.citations_endnote\n \n \nFunction\n.\n\n\ncitations_endnote(article::Dict{String,DataFrame}, verbose=false)\n\n\n\n\n\nTransforms a Dictionary of pubmed dataframes into text corresponding to its endnote citation\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.create_pmid_table!\n \n \nMethod\n.\n\n\ncreate_pmid_table!(conn; tablename=\narticle\n)\n\n\n\n\n\nCreates a table, using either MySQL of SQLite, to store PMIDs from Entrez related searches. All tables are empty at this point\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.create_tables!\n \n \nMethod\n.\n\n\ncreate_tables!(conn, medline_load=false)\n\n\n\n\n\nCreate and initialize tables to save results from an Entrez/PubMed search or a medline file load. Caution, all related tables are dropped if they exist\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.dfs_to_csv\n \n \nFunction\n.\n\n\ndfs_to_csv(dfs::Dict, path::String, [file_prefix::String])\n\n\n\n\n\nTakes output of toDataFrames and writes to CSV files at the provided path and with the file prefix.\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.get_article_mesh\n \n \nMethod\n.\n\n\nget_article_mesh(db, pmid)\n\n\n\n\n\nGet the all mesh-descriptors associated with a give article\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.get_article_mesh_by_concept\n \n \nMethod\n.\n\n\nget_article_mesh_by_concept(db, pmid, umls_concepts...; local_medline)\n\n\n\n\n\nGet the all mesh-descriptors associated with a give article\n\n\nArgumets:\n\n\n\n\nquery_string: \"\" - assumes full set of results were saved by BioMedQuery directly from XML\n\n\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.save_efetch!\n \n \nFunction\n.\n\n\nsave_efetch!(output::CitationOutput, efetch_dict, verbose=false)\n\n\n\n\n\nSave the results of a Entrez efetch to a bibliography file, with format and file path given by \noutput::CitationOutput\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.save_efetch!\n \n \nFunction\n.\n\n\npubmed_save_efetch(efetch_dict, conn)\n\n\nSave the results (dictionary) of an entrez-pubmed fetch to the input database.\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.save_pmids!\n \n \nFunction\n.\n\n\nsave_pmids!(conn, pmids::Vector{Int64}, verbose::Bool=false)\n\n\nSave a list of PMIDS into input database. ###Arguments:\n\n\n\n\nconn\n: Database connection (MySQL or SQLite)\n\n\npmids\n: Array of PMIDs\n\n\nverbose\n: Boolean to turn on extra print statements\n\n\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.all_mesh\n \n \nMethod\n.\n\n\nall_mesh(db)\n\n\n\n\n\nReturn all PMIDs stored in the \narticle\n table of the input database\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.dict_to_array\n \n \nMethod\n.\n\n\ndict_to_array(dict::Dict)\n\n\n\n\n\nGiven a dictionary, returns a tuple of arrays with the keys and values.\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.parse_MedlineDate\n \n \nMethod\n.\n\n\nparse_MedlineDate(ml_dt::String)\n\n\n\n\n\nParses the contents of the MedlineDate element and returns a tuple of the year and month.\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.parse_author\n \n \nMethod\n.\n\n\nparse_author\n\n\n\n\n\nTakes xml for author, and returns parsed elements\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.parse_month\n \n \nMethod\n.\n\n\nparse_month(mon::String)\n\n\n\n\n\nParses the string month (month or season) and returns an integer with the first month in range.\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.parse_orcid\n \n \nMethod\n.\n\n\nparse_orcid(raw_orc::String)\n\n\n\n\n\nTakes a string containing an ORC ID (url, 16 digit string) and returns a formatted ID (0000-1111-2222-3333).\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.parse_year\n \n \nMethod\n.\n\n\nparse_year(yr::String)\n\n\n\n\n\nParses the string year and returns an integer with the first year in range.\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.remove_csvs\n \n \nFunction\n.\n\n\nremove_csvs(dfs, path, file_prefix)\n\n\n\n\n\nRemoves all of the CSV files associated with a dictionary of dataframes\n\n\nsource\n\n\n#\n\n\nBioMedQuery.PubMed.remove_csvs\n \n \nMethod\n.\n\n\nremove_csvs(paths::Vector)\n\n\n\n\n\nRemoves all of the CSV files associated with an array of paths\n\n\nsource", 
            "title": "PubMed"
        }, 
        {
            "location": "/pubmed/#import-module", 
            "text": "using BioMedQuery.PubMed  This module provides utility functions to parse, store and export queries to PubMed via the NCBI EUtils and its julia interface  BioServices.EUtils . For many purposes you may interact with the higher level pipelines in [BioMedQuery.Processes]. Here, some of the lower level functions are discussed in case you need to assemble different pipelines.", 
            "title": "Import Module"
        }, 
        {
            "location": "/pubmed/#basics-of-searching-pubmed", 
            "text": "We are often interested in searching PubMed for all articles related to a search term, and possibly restricted by other search criteria. To do so we use  BioServices.EUtils . A basic example of how we may use the functions  esearch  and  efetch  to accomplish such task is illustrated below.  using   BioServices . EUtils  using   XMLDict  using   EzXML  search_term   =   obstructive sleep apnea[MeSH Major Topic]  #esearch  esearch_response   =   esearch ( db = pubmed ,   term   =   search_term ,  retstart   =   0 ,   retmax   =   20 ,   tool   = BioJulia )  #convert xml to dictionary  esearch_dict   =   parse_xml ( String ( esearch_response . data ))  #convert id s to a array of numbers  ids   =   [ parse ( Int64 ,   id_node )   for   id_node   in   esearch_dict [ IdList ][ Id ]]  #efetch  efetch_response   =   efetch ( db   =   pubmed ,   tool   =   BioJulia ,   retmode   =   xml ,   rettype   =   null ,   id   =   ids )  #convert xml to xml node tree  efetch_doc   =   root ( parsexml ( String ( efetch_response . data )))", 
            "title": "Basics of searching PubMed"
        }, 
        {
            "location": "/pubmed/#handling-xml-responses", 
            "text": "Many APIs return responses in XML form.  To parse an XML to a Julia dictionary we can use the XMLDict package  using   XMLDict  dict   =   parse_xml ( String ( response . data ))     You can save directly the XML String to file  xdoc   =   parse_string ( esearch )  save_file ( xdoc ,   ./file.xml )", 
            "title": "Handling XML responses"
        }, 
        {
            "location": "/pubmed/#save-eseachefetch-responses", 
            "text": "", 
            "title": "Save eseach/efetch responses"
        }, 
        {
            "location": "/pubmed/#save-pmids-to-mysql", 
            "text": "If we are only interseted in saving a list of PMIDs associated with a query, we can do so as follows  dbname   =   entrez_test  host   =   127.0.0.1 ;  user   =   root  pwd   =    #Collect PMIDs from esearch result  ids   =   Array { Int64 , 1 }()  for   id_node   in   esearch_dict [ IdList ][ Id ] \n     push! ( ids ,   parse ( Int64 ,   id_node ))  end  # Initialize or connect to database  const   conn   =   DBUtils . init_mysql_database ( host ,   user ,   pwd ,   dbname )  # Create `article` table to store pmids  PubMed . create_pmid_table! ( conn )  #Save pmids  PubMed . save_pmids! ( conn ,   ids )  #query the article table to explore list of pmids  all_pmids   =   BioMedQuery . PubMed . all_pmids ( conn )", 
            "title": "Save PMIDs to MySQL"
        }, 
        {
            "location": "/pubmed/#export-efetch-response-as-endnote-citation-file", 
            "text": "We can export the information returned by efetch as and EndNote/BibTex library file  citation   =   PubMed . CitationOutput ( endnote ,   ./citations_temp.endnote ,   true )  nsucceses   =   PubMed . save_efetch! ( citation ,   efetch_doc ,   verbose )", 
            "title": "Export efetch response as EndNote citation file"
        }, 
        {
            "location": "/pubmed/#save-efetch-response-to-mysql-database", 
            "text": "Save the information returned by efetch to a MySQL database  dbname   =   efetch_test  host   =   127.0.0.1 ;  user   =   root  pwd   =    # Save results of efetch to database and cleanup intermediate CSV files  const   conn   =   DBUtils . init_mysql_database ( host ,   user ,   pwd ,   dbname )  PubMed . create_tables! ( conn )  PubMed . save_efetch! ( conn ,   efetch_doc ,   false ,   true )   # verbose = false, drop_csv = true", 
            "title": "Save efetch response to MySQL database"
        }, 
        {
            "location": "/pubmed/#save-efetch-response-to-sqlite-database", 
            "text": "Save the information returned by efetch to a MySQL database  db_path   =   ./test_db.db  const   conn   =   SQLite . DB ( db_path )  PubMed . create_tables! ( conn )  PubMed . save_efetch! ( conn ,   efetch_doc )", 
            "title": "Save efetch response to SQLite database"
        }, 
        {
            "location": "/pubmed/#return-efetch-response-as-a-dictionary-of-dataframes", 
            "text": "The information returned by efetch can also be returned as dataframes. The dataframes match the format of the tables that are created for the sql saving functions (schema image below). These dataframes can also easily be saved to csv files.       dfs   =   PubMed . parse ( efetch_doc ) \n\n     PubMed . dfs_to_csv ( dfs ,   my/path ,   my_file_prefix_ )", 
            "title": "Return efetch response as a dictionary of DataFrames"
        }, 
        {
            "location": "/pubmed/#exploring-output-databases", 
            "text": "The following schema has been used to store the results. If you are interested in having this module store additional fields, feel free to open an issue           We can also explore the tables using BioMedQuery.DBUtils, e,g  tables   =   [ author_ref ,   mesh_desc ,  mesh_qual ,   mesh_heading ]  for   t   in   tables \n     query_str   =   SELECT * FROM  * t *  LIMIT 10; \n     q   =   DBUtils . db_query ( db ,   query_str ) \n     println ( q )  end", 
            "title": "Exploring output databases"
        }, 
        {
            "location": "/pubmed/#index", 
            "text": "BioMedQuery.PubMed.abstracts  BioMedQuery.PubMed.abstracts_by_year  BioMedQuery.PubMed.all_mesh  BioMedQuery.PubMed.all_pmids  BioMedQuery.PubMed.citations_bibtex  BioMedQuery.PubMed.citations_endnote  BioMedQuery.PubMed.create_pmid_table!  BioMedQuery.PubMed.create_tables!  BioMedQuery.PubMed.dfs_to_csv  BioMedQuery.PubMed.dict_to_array  BioMedQuery.PubMed.get_article_mesh  BioMedQuery.PubMed.get_article_mesh_by_concept  BioMedQuery.PubMed.parse_MedlineDate  BioMedQuery.PubMed.parse_author  BioMedQuery.PubMed.parse_month  BioMedQuery.PubMed.parse_orcid  BioMedQuery.PubMed.parse_year  BioMedQuery.PubMed.remove_csvs  BioMedQuery.PubMed.remove_csvs  BioMedQuery.PubMed.save_efetch!  BioMedQuery.PubMed.save_efetch!  BioMedQuery.PubMed.save_pmids!", 
            "title": "Index"
        }, 
        {
            "location": "/pubmed/#structs-and-functions", 
            "text": "#  Base.parse     Method .  parse(xml::EzXML.Node)  Parses a PubMedArticleSet that matches the NCBI-XML format  source  #  BioMedQuery.PubMed.abstracts     Method .  abstracts(db; local_medline=false)  Return all abstracts related to PMIDs in the database. If local_medline flag is set to true, it is assumed that db contains  basic  table with only PMIDs and all other info is available in a (same host) medline database  source  #  BioMedQuery.PubMed.abstracts_by_year     Method .  abstracts_by_year(db, pub_year; local_medline=false)  Return all abstracts of article published in the given year. If local_medline flag is set to true, it is assumed that db contains  article  table with only PMIDs and all other info is available in a (same host) medline database  source  #  BioMedQuery.PubMed.all_pmids     Method .  all_pmids(db)  Return all PMIDs stored in the  article  table of the input database  source  #  BioMedQuery.PubMed.citations_bibtex     Function .  citations_bibtex(article::Dict{String,DataFrame}, verbose=false)  Transforms a Dictionary of pubmed dataframes into text corresponding to its bibtex citation  source  #  BioMedQuery.PubMed.citations_endnote     Function .  citations_endnote(article::Dict{String,DataFrame}, verbose=false)  Transforms a Dictionary of pubmed dataframes into text corresponding to its endnote citation  source  #  BioMedQuery.PubMed.create_pmid_table!     Method .  create_pmid_table!(conn; tablename= article )  Creates a table, using either MySQL of SQLite, to store PMIDs from Entrez related searches. All tables are empty at this point  source  #  BioMedQuery.PubMed.create_tables!     Method .  create_tables!(conn, medline_load=false)  Create and initialize tables to save results from an Entrez/PubMed search or a medline file load. Caution, all related tables are dropped if they exist  source  #  BioMedQuery.PubMed.dfs_to_csv     Function .  dfs_to_csv(dfs::Dict, path::String, [file_prefix::String])  Takes output of toDataFrames and writes to CSV files at the provided path and with the file prefix.  source  #  BioMedQuery.PubMed.get_article_mesh     Method .  get_article_mesh(db, pmid)  Get the all mesh-descriptors associated with a give article  source  #  BioMedQuery.PubMed.get_article_mesh_by_concept     Method .  get_article_mesh_by_concept(db, pmid, umls_concepts...; local_medline)  Get the all mesh-descriptors associated with a give article  Argumets:   query_string: \"\" - assumes full set of results were saved by BioMedQuery directly from XML   source  #  BioMedQuery.PubMed.save_efetch!     Function .  save_efetch!(output::CitationOutput, efetch_dict, verbose=false)  Save the results of a Entrez efetch to a bibliography file, with format and file path given by  output::CitationOutput  source  #  BioMedQuery.PubMed.save_efetch!     Function .  pubmed_save_efetch(efetch_dict, conn)  Save the results (dictionary) of an entrez-pubmed fetch to the input database.  source  #  BioMedQuery.PubMed.save_pmids!     Function .  save_pmids!(conn, pmids::Vector{Int64}, verbose::Bool=false)  Save a list of PMIDS into input database. ###Arguments:   conn : Database connection (MySQL or SQLite)  pmids : Array of PMIDs  verbose : Boolean to turn on extra print statements   source  #  BioMedQuery.PubMed.all_mesh     Method .  all_mesh(db)  Return all PMIDs stored in the  article  table of the input database  source  #  BioMedQuery.PubMed.dict_to_array     Method .  dict_to_array(dict::Dict)  Given a dictionary, returns a tuple of arrays with the keys and values.  source  #  BioMedQuery.PubMed.parse_MedlineDate     Method .  parse_MedlineDate(ml_dt::String)  Parses the contents of the MedlineDate element and returns a tuple of the year and month.  source  #  BioMedQuery.PubMed.parse_author     Method .  parse_author  Takes xml for author, and returns parsed elements  source  #  BioMedQuery.PubMed.parse_month     Method .  parse_month(mon::String)  Parses the string month (month or season) and returns an integer with the first month in range.  source  #  BioMedQuery.PubMed.parse_orcid     Method .  parse_orcid(raw_orc::String)  Takes a string containing an ORC ID (url, 16 digit string) and returns a formatted ID (0000-1111-2222-3333).  source  #  BioMedQuery.PubMed.parse_year     Method .  parse_year(yr::String)  Parses the string year and returns an integer with the first year in range.  source  #  BioMedQuery.PubMed.remove_csvs     Function .  remove_csvs(dfs, path, file_prefix)  Removes all of the CSV files associated with a dictionary of dataframes  source  #  BioMedQuery.PubMed.remove_csvs     Method .  remove_csvs(paths::Vector)  Removes all of the CSV files associated with an array of paths  source", 
            "title": "Structs and Functions"
        }, 
        {
            "location": "/ct/", 
            "text": "Submit and save queries to \nclinicaltrials.gov\n\n\nImport\n\n\nusing NLM.CT\n\n\n\n\n\n\n\nSearch and save\n\n\n\n\nCreate a query:\n\n\nquery = Dict(\nterm\n =\n \nacne\n, \nage\n=\nInt(CT.child), \nlocn\n =\n \nNew York, NY\n)\n\n\n\n\n\nNote: The term can also indicate joint searches, e.g.\n\n\nterm\n =\n \naspirin OR ibuprofen\n\n\n\n\n\n\n\n\nSubmit and save:\n\n\nfout= \n./test_CT_search.zip\n\nstatus = NLM.CT.search_ct(query, fout;)", 
            "title": "Clinical Trials"
        }, 
        {
            "location": "/ct/#import", 
            "text": "using NLM.CT", 
            "title": "Import"
        }, 
        {
            "location": "/ct/#search-and-save", 
            "text": "", 
            "title": "Search and save"
        }, 
        {
            "location": "/ct/#create-a-query", 
            "text": "query = Dict( term  =   acne ,  age = Int(CT.child),  locn  =   New York, NY )  Note: The term can also indicate joint searches, e.g.  term  =   aspirin OR ibuprofen", 
            "title": "Create a query:"
        }, 
        {
            "location": "/ct/#submit-and-save", 
            "text": "fout=  ./test_CT_search.zip \nstatus = NLM.CT.search_ct(query, fout;)", 
            "title": "Submit and save:"
        }, 
        {
            "location": "/dbutils/", 
            "text": "Collection of functions that extend of simplify interactions with MySQL and SQLite databases\n\n\n\n\nImport Module\n\n\nusing BioMedQuery.DBUtils\n\n\n\n\n\n\n\nIndex\n\n\n\n\nBioMedQuery.DBUtils.assemble_cols\n\n\nBioMedQuery.DBUtils.assemble_cols_and_vals\n\n\nBioMedQuery.DBUtils.assemble_cols_and_vals_string\n\n\nBioMedQuery.DBUtils.assemble_vals\n\n\nBioMedQuery.DBUtils.col_match\n\n\nBioMedQuery.DBUtils.col_match\n\n\nBioMedQuery.DBUtils.colname_dict\n\n\nBioMedQuery.DBUtils.db_query\n\n\nBioMedQuery.DBUtils.db_query\n\n\nBioMedQuery.DBUtils.db_select\n\n\nBioMedQuery.DBUtils.disable_foreign_checks\n\n\nBioMedQuery.DBUtils.disable_foreign_checks\n\n\nBioMedQuery.DBUtils.enable_foreign_checks\n\n\nBioMedQuery.DBUtils.enable_foreign_checks\n\n\nBioMedQuery.DBUtils.init_mysql_database\n\n\nBioMedQuery.DBUtils.insert_row!\n\n\nBioMedQuery.DBUtils.insert_row!\n\n\nBioMedQuery.DBUtils.select_all_tables\n\n\nBioMedQuery.DBUtils.select_all_tables\n\n\nBioMedQuery.DBUtils.select_columns\n\n\nBioMedQuery.DBUtils.select_columns\n\n\nBioMedQuery.DBUtils.set_innodb_checks!\n\n\n\n\n\n\nFunctions\n\n\n#\n\n\nBioMedQuery.DBUtils.assemble_cols\n \n \nMethod\n.\n\n\nassemble_cols(data_values::DataFrame)\n\n\n\n\n\nGiven a DataFrame, returns a column name string formatted for an insert/load statement\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.assemble_cols_and_vals\n \n \nMethod\n.\n\n\nassemble_vals(data_values)\n\n\n\n\n\nGiven a dictionary containg (:column=\nvalue) return a single string properly formatted for a MySQL insert. E.g MySQL requires CHAR or other non-numeric values be passed with single quotes around them.\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.assemble_cols_and_vals_string\n \n \nMethod\n.\n\n\nassemble_vals(data_values)\n\n\n\n\n\nGiven a dictionary containg (:column=\nvalue), return a single string properly formatted for a MySQL SELECT. E.g MySQL requires CHAR or other non-numeric values be passed with single quotes around them.\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.assemble_vals\n \n \nMethod\n.\n\n\nassemble_vals(data_values, column_names)\n\n\n\n\n\nGiven a Dict of values and the column names, return a single string properly formatted for a MySQL INSERT. E.g MySQL requires CHAR or other non-numeric values be passed with single quotes around them.\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.col_match\n \n \nMethod\n.\n\n\ncol_match(con, tablename, col_names)\n\n\n\n\n\nChecks if each column in the csv/data frame has a matching column in the table.\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.col_match\n \n \nMethod\n.\n\n\ncol_match(con, tablename, data_values)\n\n\n\n\n\nChecks if each column in the dataframe has a matching column in the table.\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.db_query\n \n \nMethod\n.\n\n\nquery_mysql(con, query_code)\n\n\n\n\n\nExecute a mysql command\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.db_query\n \n \nMethod\n.\n\n\nquery(db, query_code)\n\n\n\n\n\nExecute a SQLite command\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.db_select\n \n \nMethod\n.\n\n\nselect_(con, colnames, tablename, data_values)\n\n\n\n\n\nPerform: SELECT colnames tablename WHERE keys(data_values)=values(data_values)\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.init_mysql_database\n \n \nFunction\n.\n\n\ninit_mysql_database(;host = \n127.0.0.1\n, dbname=\ntest\n,\nusername=\nroot\n, pswd=\n, mysql_code=nothing, overwrite=false)\n\n\n\n\n\nCreate a MySQL database using the code inside mysql_code\n\n\nArguments\n\n\n\n\nhost\n, \ndbname\n, \nuser\n, \npswd\n\n\nmysql_code::String\n: String with MySQL code that crates all default tables\n\n\noverwrite::Bool\n : Flag, if true and dbname exists, drops all database and re-creates it\n\n\n\n\nOutput\n\n\n\n\ncon\n: Database connection and table-column names map\n\n\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.insert_row!\n \n \nMethod\n.\n\n\ninsert_row!(db, tablename, values)\n\n\n\n\n\nInsert a row of values into the specified table for a given a MySQL database handle\n\n\nArguments:\n\n\n\n\ndb::MySQLDB\n: Database object (connection and map)\n\n\ndata_values::Dict{String, Any}\n: Array of (string) values\n\n\nverbose\n: Print debugginh info\n\n\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.insert_row!\n \n \nMethod\n.\n\n\ninsert_row!(db, tablename, values)\n\n\n\n\n\nInsert a row of values into the specified table for a given a SQLite database handle\n\n\nArguments:\n\n\n\n\ndb::MySQLDB\n: Database object (connection and map)\n\n\ndata_values::Dict{String, Any}\n: Array of (string) values\n\n\nverbose\n: Print debugginh info\n\n\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.select_all_tables\n \n \nMethod\n.\n\n\nselect_all_tables_mysql(con)\n\n\n\n\n\nReturn an array of all tables in a given MySQL database\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.select_all_tables\n \n \nMethod\n.\n\n\nselect_all_tables_mysql(con)\n\n\n\n\n\nReturn an array of all tables in a given MySQL database\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.set_innodb_checks!\n \n \nFunction\n.\n\n\nset_innodb_checks(conn, autocommit = 1, foreign_keys = 1, unique = 1)\n\n\n\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.colname_dict\n \n \nMethod\n.\n\n\ncolname_dict_(con)\n\n\n\n\n\nReturn a dictionary maping tables and their columns for a given MySQL-connection/SQLite-database\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.disable_foreign_checks\n \n \nMethod\n.\n\n\ndisable_foreign_checks(con::MySQL.MySQLHandle)\n\n\n\n\n\nDisables foreign checks for MySQL database\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.disable_foreign_checks\n \n \nMethod\n.\n\n\ndisable_foreign_checks(con::SQLite.DB) Disables foreign checks for SQLite database\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.enable_foreign_checks\n \n \nMethod\n.\n\n\nenable_foreign_checks(con::MySQL.MySQLHandle)\n\n\n\n\n\nEnables foreign checks for MySQL database\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.enable_foreign_checks\n \n \nMethod\n.\n\n\nenable_foreign_checks(con::SQLite.DB)\n\n\n\n\n\nEnables foreign checks for SQLite database\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.select_columns\n \n \nMethod\n.\n\n\nselect_columns_mysql(con, table)\n\n\n\n\n\nFor a MySQL database, return an array of all columns in the given table\n\n\nsource\n\n\n#\n\n\nBioMedQuery.DBUtils.select_columns\n \n \nMethod\n.\n\n\nselect_columns(db, table)\n\n\n\n\n\nReturn an array with names of columns in the given table\n\n\nsource", 
            "title": "Database Utilities"
        }, 
        {
            "location": "/dbutils/#import-module", 
            "text": "using BioMedQuery.DBUtils", 
            "title": "Import Module"
        }, 
        {
            "location": "/dbutils/#index", 
            "text": "BioMedQuery.DBUtils.assemble_cols  BioMedQuery.DBUtils.assemble_cols_and_vals  BioMedQuery.DBUtils.assemble_cols_and_vals_string  BioMedQuery.DBUtils.assemble_vals  BioMedQuery.DBUtils.col_match  BioMedQuery.DBUtils.col_match  BioMedQuery.DBUtils.colname_dict  BioMedQuery.DBUtils.db_query  BioMedQuery.DBUtils.db_query  BioMedQuery.DBUtils.db_select  BioMedQuery.DBUtils.disable_foreign_checks  BioMedQuery.DBUtils.disable_foreign_checks  BioMedQuery.DBUtils.enable_foreign_checks  BioMedQuery.DBUtils.enable_foreign_checks  BioMedQuery.DBUtils.init_mysql_database  BioMedQuery.DBUtils.insert_row!  BioMedQuery.DBUtils.insert_row!  BioMedQuery.DBUtils.select_all_tables  BioMedQuery.DBUtils.select_all_tables  BioMedQuery.DBUtils.select_columns  BioMedQuery.DBUtils.select_columns  BioMedQuery.DBUtils.set_innodb_checks!", 
            "title": "Index"
        }, 
        {
            "location": "/dbutils/#functions", 
            "text": "#  BioMedQuery.DBUtils.assemble_cols     Method .  assemble_cols(data_values::DataFrame)  Given a DataFrame, returns a column name string formatted for an insert/load statement  source  #  BioMedQuery.DBUtils.assemble_cols_and_vals     Method .  assemble_vals(data_values)  Given a dictionary containg (:column= value) return a single string properly formatted for a MySQL insert. E.g MySQL requires CHAR or other non-numeric values be passed with single quotes around them.  source  #  BioMedQuery.DBUtils.assemble_cols_and_vals_string     Method .  assemble_vals(data_values)  Given a dictionary containg (:column= value), return a single string properly formatted for a MySQL SELECT. E.g MySQL requires CHAR or other non-numeric values be passed with single quotes around them.  source  #  BioMedQuery.DBUtils.assemble_vals     Method .  assemble_vals(data_values, column_names)  Given a Dict of values and the column names, return a single string properly formatted for a MySQL INSERT. E.g MySQL requires CHAR or other non-numeric values be passed with single quotes around them.  source  #  BioMedQuery.DBUtils.col_match     Method .  col_match(con, tablename, col_names)  Checks if each column in the csv/data frame has a matching column in the table.  source  #  BioMedQuery.DBUtils.col_match     Method .  col_match(con, tablename, data_values)  Checks if each column in the dataframe has a matching column in the table.  source  #  BioMedQuery.DBUtils.db_query     Method .  query_mysql(con, query_code)  Execute a mysql command  source  #  BioMedQuery.DBUtils.db_query     Method .  query(db, query_code)  Execute a SQLite command  source  #  BioMedQuery.DBUtils.db_select     Method .  select_(con, colnames, tablename, data_values)  Perform: SELECT colnames tablename WHERE keys(data_values)=values(data_values)  source  #  BioMedQuery.DBUtils.init_mysql_database     Function .  init_mysql_database(;host =  127.0.0.1 , dbname= test ,\nusername= root , pswd= , mysql_code=nothing, overwrite=false)  Create a MySQL database using the code inside mysql_code  Arguments   host ,  dbname ,  user ,  pswd  mysql_code::String : String with MySQL code that crates all default tables  overwrite::Bool  : Flag, if true and dbname exists, drops all database and re-creates it   Output   con : Database connection and table-column names map   source  #  BioMedQuery.DBUtils.insert_row!     Method .  insert_row!(db, tablename, values)  Insert a row of values into the specified table for a given a MySQL database handle  Arguments:   db::MySQLDB : Database object (connection and map)  data_values::Dict{String, Any} : Array of (string) values  verbose : Print debugginh info   source  #  BioMedQuery.DBUtils.insert_row!     Method .  insert_row!(db, tablename, values)  Insert a row of values into the specified table for a given a SQLite database handle  Arguments:   db::MySQLDB : Database object (connection and map)  data_values::Dict{String, Any} : Array of (string) values  verbose : Print debugginh info   source  #  BioMedQuery.DBUtils.select_all_tables     Method .  select_all_tables_mysql(con)  Return an array of all tables in a given MySQL database  source  #  BioMedQuery.DBUtils.select_all_tables     Method .  select_all_tables_mysql(con)  Return an array of all tables in a given MySQL database  source  #  BioMedQuery.DBUtils.set_innodb_checks!     Function .  set_innodb_checks(conn, autocommit = 1, foreign_keys = 1, unique = 1)  source  #  BioMedQuery.DBUtils.colname_dict     Method .  colname_dict_(con)  Return a dictionary maping tables and their columns for a given MySQL-connection/SQLite-database  source  #  BioMedQuery.DBUtils.disable_foreign_checks     Method .  disable_foreign_checks(con::MySQL.MySQLHandle)  Disables foreign checks for MySQL database  source  #  BioMedQuery.DBUtils.disable_foreign_checks     Method .  disable_foreign_checks(con::SQLite.DB) Disables foreign checks for SQLite database  source  #  BioMedQuery.DBUtils.enable_foreign_checks     Method .  enable_foreign_checks(con::MySQL.MySQLHandle)  Enables foreign checks for MySQL database  source  #  BioMedQuery.DBUtils.enable_foreign_checks     Method .  enable_foreign_checks(con::SQLite.DB)  Enables foreign checks for SQLite database  source  #  BioMedQuery.DBUtils.select_columns     Method .  select_columns_mysql(con, table)  For a MySQL database, return an array of all columns in the given table  source  #  BioMedQuery.DBUtils.select_columns     Method .  select_columns(db, table)  Return an array with names of columns in the given table  source", 
            "title": "Functions"
        }, 
        {
            "location": "/library/", 
            "text": "Index\n\n\n\n\nBase.parse\n\n\nBioMedQuery.DBUtils.assemble_cols\n\n\nBioMedQuery.DBUtils.assemble_cols_and_vals\n\n\nBioMedQuery.DBUtils.assemble_cols_and_vals_string\n\n\nBioMedQuery.DBUtils.assemble_vals\n\n\nBioMedQuery.DBUtils.col_match\n\n\nBioMedQuery.DBUtils.col_match\n\n\nBioMedQuery.DBUtils.colname_dict\n\n\nBioMedQuery.DBUtils.db_query\n\n\nBioMedQuery.DBUtils.db_query\n\n\nBioMedQuery.DBUtils.db_select\n\n\nBioMedQuery.DBUtils.disable_foreign_checks\n\n\nBioMedQuery.DBUtils.disable_foreign_checks\n\n\nBioMedQuery.DBUtils.enable_foreign_checks\n\n\nBioMedQuery.DBUtils.enable_foreign_checks\n\n\nBioMedQuery.DBUtils.init_mysql_database\n\n\nBioMedQuery.DBUtils.insert_row!\n\n\nBioMedQuery.DBUtils.insert_row!\n\n\nBioMedQuery.DBUtils.select_all_tables\n\n\nBioMedQuery.DBUtils.select_all_tables\n\n\nBioMedQuery.DBUtils.select_columns\n\n\nBioMedQuery.DBUtils.select_columns\n\n\nBioMedQuery.DBUtils.set_innodb_checks!\n\n\nBioMedQuery.Processes.close_cons\n\n\nBioMedQuery.Processes.export_citation\n\n\nBioMedQuery.Processes.export_citation\n\n\nBioMedQuery.Processes.get_file_name\n\n\nBioMedQuery.Processes.get_ftp_con\n\n\nBioMedQuery.Processes.get_ml_file\n\n\nBioMedQuery.Processes.init_medline\n\n\nBioMedQuery.Processes.load_medline\n\n\nBioMedQuery.Processes.map_mesh_to_umls!\n\n\nBioMedQuery.Processes.map_mesh_to_umls_async!\n\n\nBioMedQuery.Processes.parse_ml_file\n\n\nBioMedQuery.Processes.pubmed_search_and_parse\n\n\nBioMedQuery.Processes.pubmed_search_and_save!\n\n\nBioMedQuery.Processes.umls_semantic_occurrences\n\n\nBioMedQuery.PubMed.abstracts\n\n\nBioMedQuery.PubMed.abstracts_by_year\n\n\nBioMedQuery.PubMed.all_mesh\n\n\nBioMedQuery.PubMed.all_pmids\n\n\nBioMedQuery.PubMed.citations_bibtex\n\n\nBioMedQuery.PubMed.citations_endnote\n\n\nBioMedQuery.PubMed.create_pmid_table!\n\n\nBioMedQuery.PubMed.create_tables!\n\n\nBioMedQuery.PubMed.dfs_to_csv\n\n\nBioMedQuery.PubMed.dict_to_array\n\n\nBioMedQuery.PubMed.get_article_mesh\n\n\nBioMedQuery.PubMed.get_article_mesh_by_concept\n\n\nBioMedQuery.PubMed.parse_MedlineDate\n\n\nBioMedQuery.PubMed.parse_author\n\n\nBioMedQuery.PubMed.parse_month\n\n\nBioMedQuery.PubMed.parse_orcid\n\n\nBioMedQuery.PubMed.parse_year\n\n\nBioMedQuery.PubMed.remove_csvs\n\n\nBioMedQuery.PubMed.remove_csvs\n\n\nBioMedQuery.PubMed.save_efetch!\n\n\nBioMedQuery.PubMed.save_efetch!\n\n\nBioMedQuery.PubMed.save_pmids!", 
            "title": "Library"
        }, 
        {
            "location": "/library/#index", 
            "text": "Base.parse  BioMedQuery.DBUtils.assemble_cols  BioMedQuery.DBUtils.assemble_cols_and_vals  BioMedQuery.DBUtils.assemble_cols_and_vals_string  BioMedQuery.DBUtils.assemble_vals  BioMedQuery.DBUtils.col_match  BioMedQuery.DBUtils.col_match  BioMedQuery.DBUtils.colname_dict  BioMedQuery.DBUtils.db_query  BioMedQuery.DBUtils.db_query  BioMedQuery.DBUtils.db_select  BioMedQuery.DBUtils.disable_foreign_checks  BioMedQuery.DBUtils.disable_foreign_checks  BioMedQuery.DBUtils.enable_foreign_checks  BioMedQuery.DBUtils.enable_foreign_checks  BioMedQuery.DBUtils.init_mysql_database  BioMedQuery.DBUtils.insert_row!  BioMedQuery.DBUtils.insert_row!  BioMedQuery.DBUtils.select_all_tables  BioMedQuery.DBUtils.select_all_tables  BioMedQuery.DBUtils.select_columns  BioMedQuery.DBUtils.select_columns  BioMedQuery.DBUtils.set_innodb_checks!  BioMedQuery.Processes.close_cons  BioMedQuery.Processes.export_citation  BioMedQuery.Processes.export_citation  BioMedQuery.Processes.get_file_name  BioMedQuery.Processes.get_ftp_con  BioMedQuery.Processes.get_ml_file  BioMedQuery.Processes.init_medline  BioMedQuery.Processes.load_medline  BioMedQuery.Processes.map_mesh_to_umls!  BioMedQuery.Processes.map_mesh_to_umls_async!  BioMedQuery.Processes.parse_ml_file  BioMedQuery.Processes.pubmed_search_and_parse  BioMedQuery.Processes.pubmed_search_and_save!  BioMedQuery.Processes.umls_semantic_occurrences  BioMedQuery.PubMed.abstracts  BioMedQuery.PubMed.abstracts_by_year  BioMedQuery.PubMed.all_mesh  BioMedQuery.PubMed.all_pmids  BioMedQuery.PubMed.citations_bibtex  BioMedQuery.PubMed.citations_endnote  BioMedQuery.PubMed.create_pmid_table!  BioMedQuery.PubMed.create_tables!  BioMedQuery.PubMed.dfs_to_csv  BioMedQuery.PubMed.dict_to_array  BioMedQuery.PubMed.get_article_mesh  BioMedQuery.PubMed.get_article_mesh_by_concept  BioMedQuery.PubMed.parse_MedlineDate  BioMedQuery.PubMed.parse_author  BioMedQuery.PubMed.parse_month  BioMedQuery.PubMed.parse_orcid  BioMedQuery.PubMed.parse_year  BioMedQuery.PubMed.remove_csvs  BioMedQuery.PubMed.remove_csvs  BioMedQuery.PubMed.save_efetch!  BioMedQuery.PubMed.save_efetch!  BioMedQuery.PubMed.save_pmids!", 
            "title": "Index"
        }
    ]
}